{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OSIooWCGCLoW",
        "outputId": "84acd988-70ba-4120-c3e0-f34063cfe6d4"
      },
      "outputs": [],
      "source": [
        "# @title Setup packages\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import random\n",
        "#from google.colab import output\n",
        "import json\n",
        "import time\n",
        "from bs4 import BeautifulSoup\n",
        "import random\n",
        "import requests\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import spacy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsNBWjF-oGJw",
        "outputId": "d1b7a9c9-fd3c-4b8f-e76c-cfaa1a625f6a"
      },
      "outputs": [],
      "source": [
        "# # magic needed to just let importing openAI work\n",
        "# %%writefile /usr/local/lib/python3.10/dist-packages/openai/_utils/_streams.py\n",
        "# from typing import Any\n",
        "# from typing_extensions import AsyncIterator\n",
        "# from typing import Iterator # import Iterator from the correct library\n",
        "\n",
        "# def consume_sync_iterator(iterator: Iterator[Any]) -> None:\n",
        "#     for _ in iterator:\n",
        "#         ...\n",
        "\n",
        "# async def consume_async_iterator(iterator: AsyncIterator[Any]) -> None:\n",
        "#     async for _ in iterator:\n",
        "#         ...\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "8ttg4CvtpZlM"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "p8fwFFTDoiz9"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"en_core_web_trf\")\n",
        "\n",
        "sns.set(context=\"poster\", style='white')\n",
        "#output.clear()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsC4XN7TOgfN",
        "outputId": "be7b17d0-dd91-4d5f-8a7b-c7c8fc0ea339"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scraping page: 1\n",
            "URL: https://www.politifact.com/factchecks/list/?page=1&category=elections\n",
            "Scraping page: 2\n",
            "URL: https://www.politifact.com/factchecks/list/?page=2&category=elections\n",
            "Scraping page: 3\n",
            "URL: https://www.politifact.com/factchecks/list/?page=3&category=elections\n",
            "Scraping page: 4\n",
            "URL: https://www.politifact.com/factchecks/list/?page=4&category=elections\n",
            "Scraping page: 5\n",
            "URL: https://www.politifact.com/factchecks/list/?page=5&category=elections\n",
            "Scraping page: 6\n",
            "URL: https://www.politifact.com/factchecks/list/?page=6&category=elections\n",
            "Scraping page: 7\n",
            "URL: https://www.politifact.com/factchecks/list/?page=7&category=elections\n",
            "Scraping page: 8\n",
            "URL: https://www.politifact.com/factchecks/list/?page=8&category=elections\n",
            "Scraping page: 9\n",
            "URL: https://www.politifact.com/factchecks/list/?page=9&category=elections\n",
            "Number of claims scraped where truth value is in false OR pants-fire:  194\n"
          ]
        }
      ],
      "source": [
        "# @title Get a list of election-related misinformation from PolitiFact.\n",
        "# @markdown ToDos: Filter on date, Extract source of claim\n",
        "\n",
        "def flatten_list_of_lists(list_of_lists):\n",
        "    return [item for sublist in list_of_lists for item in sublist]\n",
        "\n",
        "def scrape_election_claims(pg_no):\n",
        "    \"\"\"\n",
        "    Scrapes election related claims and their truth values from Politifact\n",
        "\n",
        "    Params\n",
        "    - pg_no (int): Page number\n",
        "\n",
        "    Returns\n",
        "    - A list of tuples with each tuple containing a claim and its truth value\n",
        "    \"\"\"\n",
        "    url = f\"https://www.politifact.com/factchecks/list/?page={pg_no}&category=elections\"\n",
        "    print(\"Scraping page:\", pg_no)\n",
        "    print(\"URL:\", url)\n",
        "\n",
        "    time.sleep(random.random())\n",
        "    claims_data = []\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        try:\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "            claims = soup.find_all('div', class_='m-statement__quote')\n",
        "            truth_values = soup.find_all('div', class_='m-statement__meter')\n",
        "\n",
        "            for claim, truth_value in zip(claims, truth_values):\n",
        "                claim_text = claim.get_text(strip=True)\n",
        "                truth_value_text = truth_value.find('img').get('alt')  # Assuming the truth value is in an image alt text\n",
        "                claims_data.append((claim_text, truth_value_text))\n",
        "        except Exception as e:\n",
        "            print(f\"Retrieved page but couldn't parse claims for page {pg_no} due to {e}\")\n",
        "    else:\n",
        "        print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n",
        "    return claims_data\n",
        "\n",
        "\n",
        "\n",
        "claims = [scrape_election_claims(pg_no=i) for i in range(1, 10)]\n",
        "claims = flatten_list_of_lists(claims)\n",
        "claim_df = pd.DataFrame(claims, columns=['claim', 'truth'])\n",
        "false_flags = ['false', 'pants-fire']\n",
        "claim_df = claim_df.query(\"truth in @ false_flags\")\n",
        "print(f\"Number of claims scraped where truth value is in {' OR '.join([x for x in false_flags])}: \", len(claim_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Nhp9ygRh80db",
        "outputId": "d0fa0255-c28c-43c3-8231-3f163963b3e0"
      },
      "outputs": [],
      "source": [
        "# @title Get named entities.\n",
        "# @markdown It takes awhile using Spacy Transformers. ToDos:  (1) Better filter out non-useful named entities such as numbers and (2) filter out duplicates like \"Biden\" and \"Joe Biden\"\n",
        "def extract_named_entities(nlp, text):\n",
        "  \"\"\"Extract named entities from text using Spacy tagger\"\"\"\n",
        "  doc = nlp(text)\n",
        "  entities = [ent.text for ent in doc.ents]\n",
        "  return entities\n",
        "def refine_entities(entities):\n",
        "    \"\"\"\n",
        "    Refine a list of entities by removing any entities containing numbers and merging duplicate names.\n",
        "    \n",
        "    Args:\n",
        "    entities (list): A list of entity strings.\n",
        "    \n",
        "    Returns:\n",
        "    list: A refined list of entities without duplicates and entities containing numbers.\n",
        "    \"\"\"\n",
        "    refined_entities = []\n",
        "    seen = set()  # To track seen entities and avoid re-adding them\n",
        "\n",
        "    # Remove entities containing numeric characters\n",
        "    non_numeric_entities = [entity for entity in entities if not any(char.isdigit() for char in entity)]\n",
        "    \n",
        "    for entity in non_numeric_entities:\n",
        "        # Simplify comparison by using lowercase\n",
        "        lower_entity = entity.lower()\n",
        "\n",
        "        # Check for partial matches (e.g., \"biden\" with \"joe biden\")\n",
        "        partial_match_found = False\n",
        "        for seen_entity in list(seen):\n",
        "            if lower_entity in seen_entity or seen_entity in lower_entity:\n",
        "                # Merge names by keeping the longer one\n",
        "                if len(lower_entity) > len(seen_entity):\n",
        "                    seen.remove(seen_entity)\n",
        "                    seen.add(lower_entity)\n",
        "                    refined_entities.remove(seen_entity.capitalize())\n",
        "                    refined_entities.append(entity)\n",
        "                partial_match_found = True\n",
        "                break\n",
        "\n",
        "        if not partial_match_found and lower_entity not in seen:\n",
        "            seen.add(lower_entity)\n",
        "            refined_entities.append(entity)\n",
        "\n",
        "    return refined_entities\n",
        "\n",
        "def gen_entities(entity_probabilities, n=2):\n",
        "  \"\"\"\n",
        "  Generate entities according to weights of occurence in dataset\n",
        "\n",
        "  Params:\n",
        "    entity_probabilities (dict): A dict like {entity: probability}\n",
        "\n",
        "  Returns a list of `n` entities\n",
        "  \"\"\"\n",
        "  return random.choices(list(entity_probabilities.keys()), weights=entity_probabilities.values(), k=n)\n",
        "\n",
        "def gen_claims(claims, n=2):\n",
        "  \"\"\"Generate a random sample of claims\"\"\"\n",
        "  return random.sample(list(claims), k=n)\n",
        "\n",
        "# Get named entities\n",
        "entities_per_claim = [extract_named_entities(nlp, claim) for claim in claim_df['claim'].unique()]\n",
        "refined_entities_list = []\n",
        "for entities in entities_per_claim:\n",
        "    refined_entities = refine_entities(entities)\n",
        "    refined_entities_list.append(refined_entities)\n",
        "\n",
        "# # Make distribution\n",
        "entity_frequency = Counter([entity for sublist in refined_entities_list for entity in sublist])\n",
        "total_entities = sum(entity_frequency.values())\n",
        "entity_probabilities = {entity: freq / total_entities for entity, freq in entity_frequency.items()}\n",
        "\n",
        "# # Plot some entity distributions\n",
        "# prob_df = pd.DataFrame(entity_probabilities, index=[1]).T.reset_index()\n",
        "# prob_df.columns = ['entity', 'prob']\n",
        "# prob_df = prob_df.sort_values(by=['prob'], ascending=False)\n",
        "\n",
        "# plt.figure(figsize=(12,8))\n",
        "# sns.histplot(prob_df['prob'])\n",
        "# plt.title(f\"Probability Distribution of {prob_df['entity'].nunique()} Named Entities\")\n",
        "# plt.ylabel(\"Number of Entities\")\n",
        "# plt.xlabel(\"Probability of Occurence\")\n",
        "# plt.show()\n",
        "\n",
        "# plt.figure(figsize=(12,8))\n",
        "# sns.barplot(data=prob_df.head(20), x='prob', y='entity', palette='Blues_r')\n",
        "# plt.title(\"Top 20 Named Entities\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_3lUURz_Cbt"
      },
      "source": [
        "# Generate similar misinformation using a few-shot prompt.\n",
        "\n",
        "- CONTEXT: We provide `N_EXAMPLES` of claims and `N_EXAMPLES` of named entities, where the probability of a named entity being picked is proportional to its probability in the dataset\n",
        "\n",
        "- PROMPT: Ask ChatGPT to generate `N_STATEMENTS` similar to the example claims, where each claim is about at least one of the named entities.\n",
        "\n",
        "- CONSTRAINTS: By default we say `Each statement should sound very realistic.` but can experiment by tweaking `MORE_INSTRUCTIONS`\n",
        "\n",
        "Possible ToDos: Prompt experiments, change hyperparameters, add source, source-entity co-occurence, fine-tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jiaTOZtIDMfI",
        "outputId": "2aa4a880-2adb-43eb-f5ba-e13dc0e4c360"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PROMPT:\n",
            "\n",
            " Generate 10 statement(s) similar to these statements: \n",
            "-“There is no chain of custody” for ballots placed in Box No. 3 at Maricopa, Arizona, polling sites. \n",
            "-“Maricopa County announced that on Election Day over 540,000 voters visited one of the 223” vote centers, but final official results data claimed that “only 248,070 people voted.” \n",
            "-“Illegal immigrants now have the right to vote in New York.\" \n",
            "-Vice President Mike Pence on Jan. 6, 2021, could have approved the 2020 electoral votes on the condition that Congress pass an overhaul of election law. \n",
            "-“In Arizona, we have flood the zone with fake ballots.” \n",
            "-“They are trying to make it illegal to question the results of a bad election.” \n",
            "-If Texas says, “‘We don’t want to be part of America anymore’ … that’s their decision to make.” \n",
            "-“Pennsylvania is under a court order to count their ballots on election day and not after!!” \n",
            "-Brian Kemp \"dismissed concerns about voter fraud in the 2020 election\" and \"widespread illegal ballot harvesting continued, electing two Democrat senators.\" \n",
            "-Regarding Trump’s January 2021 telephone call with Georgia election officials, “nobody found anything wrong with that perfect call until a book promotion tour many months later.”\n",
            "\n",
            "Each statement should be about at least one of these entities:\n",
            "-Los Angeles County \n",
            "-days \n",
            "-Katie Hobbs \n",
            "-third \n",
            "-DMV \n",
            "-Arizona \n",
            "-Clark County \n",
            "-Biden \n",
            "-Zero \n",
            "-Brazilian\n",
            "\n",
            "Return a newline-seperated list of statements and nothing else.\n",
            "\n",
            "STATEMENTS:\n",
            "-Statement1 \n",
            "-Statement2\n",
            "...\n",
            "CONSTRAINTS:\n",
            "-Each statement should sound very realistic.\n",
            "\n",
            "\n",
            "\n",
            "RESPONSE:\n",
            "\n",
            " -There is no chain of custody for ballots placed in Box No. 3 at the Los Angeles County polling sites.\n",
            "-Maricopa County announced that on Election Day over 540,000 voters visited one of the 223 vote centers, but final official results data claimed that only 248,070 people voted in Clark County.\n",
            "-Katie Hobbs has been advocating for stricter voting regulations in Arizona.\n",
            "-It has been discovered that a third of the ballots counted in the DMV district were found to be invalid.\n",
            "-Illegal immigrants now have the right to vote in Los Angeles County.\n",
            "-Vice President Biden on Jan. 6, 2021, could have approved the 2020 electoral votes on the condition that Congress pass an overhaul of election law.\n",
            "-In Arizona, we have witnessed zero instances of voter fraud in the recent elections.\n",
            "-They are trying to make it illegal to question the results of a bad election in Clark County.\n",
            "-If Texas says, \"We don't want to be part of America anymore\"... that's their decision to make according to the DMV regulations.\n",
            "-Pennsylvania is under a court order to count their ballots on Election Day and not after in Los Angeles County.\n"
          ]
        }
      ],
      "source": [
        "# @title Prompt Generator { vertical-output: true }\n",
        "N_STATEMENTS = 10# @param {type:\"slider\", min:1, max:10, step:1}\n",
        "N_EXAMPLES =  10# @param {type:\"slider\", min:1, max:10, step:1}\n",
        "MODEL = \"gpt-3.5-turbo\" # @param [\"gpt-3.5-turbo\", \"gpt-4\"]\n",
        "MORE_INSTRUCTIONS = \"\" # @param {type:\"string\"}\n",
        "OPENAI_KEY = \"\" # @param {type:\"string\"}\n",
        "\n",
        "def query_openai(prompt, model):\n",
        "  \"\"\"Query openai\"\"\"\n",
        "  client = OpenAI(api_key=OPENAI_KEY)\n",
        "  response = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=[\n",
        "      {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt\n",
        "      },\n",
        "    ],\n",
        "    temperature=1,\n",
        "    max_tokens=256,\n",
        "    top_p=1,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0\n",
        "  )\n",
        "  return json.loads(response.json())['choices'][0]['message']['content']\n",
        "\n",
        "\n",
        "def get_prompt(entity_probabilities, claims, n_statements=1, n_examples=2, more_instructions=\"\"):\n",
        "  \"\"\"\n",
        "  Build a prompt for few shot misinfo generation\n",
        "\n",
        "  Params\n",
        "  - entity_probabilities (dict): {entity, prob} dictionary\n",
        "  - claims (list): A list of claims\n",
        "  - n_statements(int, default=1): Number of statements to generate\n",
        "  - n_examples (int, default=2): Number of examples\n",
        "  - more_instructions (str, default=''): A string of addtnl instructions\n",
        "\n",
        "  Returns:\n",
        "    A string of a ChatGPT prompt\n",
        "\n",
        "  \"\"\"\n",
        "  claims = '-' + \" \\n-\".join([x for x in set(gen_claims(claims, n=n_examples))])\n",
        "  entities = '-' + \" \\n-\".join([x for x in  set(gen_entities(entity_probabilities, n=n_examples))])\n",
        "\n",
        "  prompt = f\"\"\"Generate {n_statements} statement(s) similar to these statements: \\n{claims}\\n\\nEach statement should be about at least one of these entities:\\n{entities}\\n\\nReturn a newline-seperated list of statements and nothing else.\\n\\nSTATEMENTS:\\n-Statement1 \\n-Statement2\\n...\\nCONSTRAINTS:\\n-Each statement should sound very realistic.\\n{'-' + more_instructions if more_instructions else ''}\\n\\n\"\"\"\n",
        "  return entities, prompt\n",
        "\n",
        "extracted_entities, prompt = get_prompt(entity_probabilities, claim_df['claim'].values, n_statements=N_STATEMENTS, n_examples=N_EXAMPLES, more_instructions=MORE_INSTRUCTIONS)\n",
        "print(\"PROMPT:\\n\\n\", prompt)\n",
        "\n",
        "response = query_openai(prompt, MODEL)\n",
        "print(\"RESPONSE:\\n\\n\", response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List of all GPT-generated statments\n",
        "statements_list = response.strip().split('\\n')\n",
        "statements_list = [statement.lstrip('-') for statement in statements_list]\n",
        "candidates=statements_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List of all entities used to generated all the statements\n",
        "extracted_entities_list = extracted_entities.strip().split('\\n')\n",
        "extracted_entities_list = [extracted_entities_list.lstrip('-') for extracted_entities_list in extracted_entities_list]\n",
        "extracted_entities_list = [extracted_entities_list.rstrip() for extracted_entities_list in extracted_entities_list]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['Los Angeles County'], ['Clark County'], ['Katie Hobbs', 'Arizona'], ['third', 'DMV'], ['Los Angeles County'], ['Biden'], ['Arizona', 'Zero'], ['Clark County'], ['DMV'], ['Los Angeles County']]\n"
          ]
        }
      ],
      "source": [
        "# Link all the entities with the statements and form a list\n",
        "entities_in_statements = []\n",
        "for statement in statements_list:\n",
        "    entities_in_current_statement = [entity for entity in extracted_entities_list if entity.lower() in statement.lower()]\n",
        "    entities_in_statements.append(entities_in_current_statement)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Search out all the rows that had any of the entities that the each of the generated statements used\n",
        "filtered_rows=[]\n",
        "for entities_per_statement in entities_in_statements:\n",
        "    filtered_rows_per_statement = [index for index, row in enumerate(entities_per_claim) if any(element in entities_per_statement for element in row)]\n",
        "    filtered_rows.append(filtered_rows_per_statement)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['“Wisconsin has historically … and I think largely continues to be, a blue state.”'],\n",
              " ['Photo shows a copycat ‘QAnon shaman’ at attack on Brazil’s capital.',\n",
              "  '\"Over 240,000 \\'unverified\\' ballots have already been sent out in Pennsylvania, a total mess. The Democrats are playing games again.”'],\n",
              " ['Clips of Nikki Haley speaking about Hillary Clinton show Haley supports Clinton and is “not who she says she is.”',\n",
              "  '\"Trump has selected his pick for running mate (and the) news stuns Republican Party.”',\n",
              "  'Ron DeSantis “wants to cut Social Security and Medicare.”',\n",
              "  'Video showing someone in military gear outside a Georgia Waffle House proves that Donald Trump is president.',\n",
              "  'A lawyer for former President Donald Trump released new proof of 2020 election fraud.',\n",
              "  'An Arizona judge was “forced to overturn” an election and ruled “274,000 ballots must be thrown out.”',\n",
              "  'A Florida elections bill “guts everything” “instead of getting tough, and doing what the people want (same day voting, Voter ID, proof of Citizenship, paper ballots, hand count, etc.).”',\n",
              "  'A video shows Florida Gov. Ron DeSantis saying, “Now Trump’s been indicted, now the people will have no choice but to accept me as their assigned candidate.”',\n",
              "  'Regarding Trump’s January 2021 telephone call with Georgia election officials, “nobody found anything wrong with that perfect call until a book promotion tour many months later.”',\n",
              "  'Wake County is the only large county in North Carolina that elects its commissioners at-large countywide.',\n",
              "  'Glenn Youngkin is “the first sitting Governor in the modern era to have their party have less legislative seats than when they were elected.”',\n",
              "  'Photo shows a copycat ‘QAnon shaman’ at attack on Brazil’s capital.',\n",
              "  'Elon Musk tweeted, “The Democrats paid the CEO Jack Dorsey of Twitter millions of dollars to block and delete people’s pages during the 2020 election.”',\n",
              "  'On the day of the Dec. 6 runoff, “armed groups of Black Panthers” were “reportedly patrolling certain voting locations” in Georgia.',\n",
              "  '“Republicans want to raise the voting to age 28.”',\n",
              "  'U.S. tax dollars sent to help Ukraine were laundered back by cryptocurrency firm FTX to help Democrats in midterms.',\n",
              "  'Graph shows Gretchen Whitmer stole the Michigan gubernatorial election.',\n",
              "  '“Minnesota was stolen from Scott Jensen.”',\n",
              "  'Suggests that “since mostly Democrats vote early” then that represents “made-up ballots or dead people voting.”',\n",
              "  'The U.S. “could easily count every vote in every state on election night until a few years ago.”',\n",
              "  'Kari Lake and Mark Finchem “have said that they will only honor the results of an election if they agree with it.\"',\n",
              "  'Says Mandela Barnes “supported a 20% increase in the gas tax.”'],\n",
              " ['Says President Joe Biden said that Democrats should not vote in the New Hampshire primary.',\n",
              "  '“So the Pennsylvania Supreme Court just ruled, in effect, that the 2020 presidential election was rigged.”'],\n",
              " ['“Wisconsin has historically … and I think largely continues to be, a blue state.”'],\n",
              " ['Biden’s strategy is to “get as many illegals in the country as possible” and “legalize them to create a permanent majority.”',\n",
              "  'Democrats “used COVID to cheat” in the 2020 election.',\n",
              "  '“Maricopa County intentionally reduced the polling places.”',\n",
              "  'Former President Jimmy Carter said “don’t ever use” mail in ballots because “they can be so easily corrupted.”',\n",
              "  'Document shows Rebekah Jones “demonstrated” a violation of Florida’s Whistleblower Act.',\n",
              "  '“I don’t care for mail-in voting. That’s why I go to the polls.”',\n",
              "  'Says Mandela Barnes “supported a 20% increase in the gas tax.”'],\n",
              " ['Clips of Nikki Haley speaking about Hillary Clinton show Haley supports Clinton and is “not who she says she is.”',\n",
              "  '\"Trump has selected his pick for running mate (and the) news stuns Republican Party.”',\n",
              "  'Ron DeSantis “wants to cut Social Security and Medicare.”',\n",
              "  'Video showing someone in military gear outside a Georgia Waffle House proves that Donald Trump is president.',\n",
              "  'A lawyer for former President Donald Trump released new proof of 2020 election fraud.',\n",
              "  'A Florida elections bill “guts everything” “instead of getting tough, and doing what the people want (same day voting, Voter ID, proof of Citizenship, paper ballots, hand count, etc.).”',\n",
              "  'A video shows Florida Gov. Ron DeSantis saying, “Now Trump’s been indicted, now the people will have no choice but to accept me as their assigned candidate.”',\n",
              "  'Regarding Trump’s January 2021 telephone call with Georgia election officials, “nobody found anything wrong with that perfect call until a book promotion tour many months later.”',\n",
              "  'Glenn Youngkin is “the first sitting Governor in the modern era to have their party have less legislative seats than when they were elected.”',\n",
              "  'Photo shows a copycat ‘QAnon shaman’ at attack on Brazil’s capital.',\n",
              "  'Elon Musk tweeted, “The Democrats paid the CEO Jack Dorsey of Twitter millions of dollars to block and delete people’s pages during the 2020 election.”',\n",
              "  'On the day of the Dec. 6 runoff, “armed groups of Black Panthers” were “reportedly patrolling certain voting locations” in Georgia.',\n",
              "  '“Republicans want to raise the voting to age 28.”',\n",
              "  'U.S. tax dollars sent to help Ukraine were laundered back by cryptocurrency firm FTX to help Democrats in midterms.',\n",
              "  'Graph shows Gretchen Whitmer stole the Michigan gubernatorial election.',\n",
              "  '“Minnesota was stolen from Scott Jensen.”',\n",
              "  'Video suggests GOP voters denied access in general election.',\n",
              "  'Suggests that “since mostly Democrats vote early” then that represents “made-up ballots or dead people voting.”',\n",
              "  'The U.S. “could easily count every vote in every state on election night until a few years ago.”',\n",
              "  'Kari Lake and Mark Finchem “have said that they will only honor the results of an election if they agree with it.\"',\n",
              "  'Says Mandela Barnes “supported a 20% increase in the gas tax.”'],\n",
              " ['Photo shows a copycat ‘QAnon shaman’ at attack on Brazil’s capital.',\n",
              "  '\"Over 240,000 \\'unverified\\' ballots have already been sent out in Pennsylvania, a total mess. The Democrats are playing games again.”'],\n",
              " ['“So the Pennsylvania Supreme Court just ruled, in effect, that the 2020 presidential election was rigged.”'],\n",
              " ['“Wisconsin has historically … and I think largely continues to be, a blue state.”']]"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Gernerating the list of existing statements\n",
        "references=[]\n",
        "for row_list in filtered_rows:\n",
        "    references_per_statement=[]\n",
        "    for row_num in row_list:\n",
        "        references_per_statement.append(claims[row_num][0])\n",
        "    references.append(references_per_statement)\n",
        "references"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([0.83681005, 0.85647386, 0.86977142, 0.87489086, 0.84713727,\n",
              "       0.8683508 , 0.88615865, 0.86073941, 0.84644192, 0.83464378])"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from bert_score import score\n",
        "import numpy as np\n",
        "\n",
        "# Initialize an array to store the best F1 score for each candidate\n",
        "best_f1_scores = np.zeros(len(candidates))\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# Compare each candidate against every reference\n",
        "for i, candidate in enumerate(candidates):\n",
        "    reference_list=references[i]\n",
        "    # Store F1 scores for the current candidate against all references\n",
        "    f1_scores_for_candidate = []\n",
        "    \n",
        "    for reference in reference_list:\n",
        "        P, R, F1 = score([candidate], [reference], lang='en', verbose=False)\n",
        "        f1_scores_for_candidate.append(F1.item())\n",
        "    \n",
        "    # Find the best F1 score for the current candidate\n",
        "    best_f1_scores[i] = max(f1_scores_for_candidate)\n",
        "\n",
        "best_f1_scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA is not available. Computation will fall back on the CPU.\n"
          ]
        }
      ],
      "source": [
        "#junk\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA is available. GPU will be used for computation.\")\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    print(\"CUDA is not available. Computation will fall back on the CPU.\")\n",
        "    device = torch.device(\"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#junk for now\n",
        "def Calc_Bert_Score(repeats=5):\n",
        "    for i in range(repeats): \n",
        "        extracted_entities, prompt = get_prompt(entity_probabilities, claim_df['claim'].values, n_statements=N_STATEMENTS, n_examples=N_EXAMPLES, more_instructions=MORE_INSTRUCTIONS)\n",
        "        response = query_openai(prompt, MODEL)\n",
        "        statements_list = response.strip().split('\\n')\n",
        "        statements_list = [statement.lstrip('-') for statement in statements_list]\n",
        "        extracted_entities_list = extracted_entities.strip().split('\\n')\n",
        "        extracted_entities_list = [extracted_entities_list.lstrip('-') for extracted_entities_list in extracted_entities_list]\n",
        "        extracted_entities_list = [extracted_entities_list.rstrip() for extracted_entities_list in extracted_entities_list]\n",
        "        filtered_rows = [index for index, row in enumerate(entities_per_claim) if any(element in extracted_entities_list for element in row)]\n",
        "        references=[]\n",
        "        for row_num in filtered_rows:\n",
        "            references.append(claims[row_num][0])\n",
        "        candidates=statements_list\n",
        "\n",
        "    "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
